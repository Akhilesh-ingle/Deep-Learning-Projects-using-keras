{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_cat_dog.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ynhyXjrZ0Al"
      },
      "source": [
        "# Convlutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ7A9H00Z9_L"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlJ5Gd6cKMiv",
        "outputId": "aaaa358d-5856-4321-b13e-befad1a3ee58"
      },
      "source": [
        "# Mounting Drive\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utTh2QaKKnM5"
      },
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOvXH7dWLhp6"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hXqD5a43Lqcm",
        "outputId": "310d8f35-716c-4582-f03d-3076ed85fd8f"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyZHTBKnZ-9v"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYCqOWT8Ls6_",
        "outputId": "04468f5c-0173-43cb-fec1-2b4277a82696"
      },
      "source": [
        "# Loading images into training set\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "train_datagen = image.ImageDataGenerator(rescale = 1./255,\n",
        "                                         shear_range = 0.2,\n",
        "                                         zoom_range = 0.2,\n",
        "                                         horizontal_flip = True)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/CNN_Model/dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQoF58iyNQVA",
        "outputId": "fbafb9b8-7306-4ce7-a1ad-5e22215d24fe"
      },
      "source": [
        "# Loading images into test set\n",
        "\n",
        "test_datagen = image.ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/drive/MyDrive/CNN_Model/dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpg5mQ_TaADx"
      },
      "source": [
        "## Building the CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6vH3xdtOHmC"
      },
      "source": [
        "# Creating a Sequential Model\n",
        "\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', input_shape = [64, 64, 3]),\n",
        "                          keras.layers.MaxPool2D(pool_size = 2, strides = 2),\n",
        "\n",
        "                          keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu'),\n",
        "                          keras.layers.MaxPool2D(pool_size = 2, strides = 2),\n",
        "\n",
        "                          keras.layers.Flatten(),\n",
        "                          keras.layers.Dense(128, activation = 'relu'),\n",
        "\n",
        "                          keras.layers.Dense(1, activation = 'sigmoid')\n",
        "                          ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lezt5bEnP6Wu"
      },
      "source": [
        "# Compiling our model\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezNep3m6RNnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9938dd8-f1b1-466f-b03a-6ae3f3aa4d3c"
      },
      "source": [
        "# Training our Model\n",
        "\n",
        "model.fit(x = training_set, validation_data = test_set,\n",
        "          epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "250/250 [==============================] - 43s 169ms/step - loss: 0.6913 - accuracy: 0.5402 - val_loss: 0.6047 - val_accuracy: 0.6815\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 39s 157ms/step - loss: 0.6195 - accuracy: 0.6580 - val_loss: 0.5659 - val_accuracy: 0.7075\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 41s 166ms/step - loss: 0.5619 - accuracy: 0.7070 - val_loss: 0.5373 - val_accuracy: 0.7345\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 41s 166ms/step - loss: 0.5267 - accuracy: 0.7423 - val_loss: 0.5141 - val_accuracy: 0.7540\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.5114 - accuracy: 0.7453 - val_loss: 0.5220 - val_accuracy: 0.7650\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.4854 - accuracy: 0.7631 - val_loss: 0.5179 - val_accuracy: 0.7600\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.4760 - accuracy: 0.7706 - val_loss: 0.5038 - val_accuracy: 0.7660\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.4693 - accuracy: 0.7689 - val_loss: 0.5036 - val_accuracy: 0.7580\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 42s 166ms/step - loss: 0.4584 - accuracy: 0.7819 - val_loss: 0.4784 - val_accuracy: 0.7755\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.4340 - accuracy: 0.7905 - val_loss: 0.4813 - val_accuracy: 0.7815\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 41s 165ms/step - loss: 0.4118 - accuracy: 0.8108 - val_loss: 0.4925 - val_accuracy: 0.7770\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 41s 165ms/step - loss: 0.4039 - accuracy: 0.8086 - val_loss: 0.4946 - val_accuracy: 0.7720\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.3979 - accuracy: 0.8155 - val_loss: 0.4520 - val_accuracy: 0.8045\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 42s 166ms/step - loss: 0.3872 - accuracy: 0.8254 - val_loss: 0.4588 - val_accuracy: 0.8000\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 42s 168ms/step - loss: 0.3757 - accuracy: 0.8341 - val_loss: 0.4642 - val_accuracy: 0.7950\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 39s 157ms/step - loss: 0.3724 - accuracy: 0.8349 - val_loss: 0.5159 - val_accuracy: 0.7715\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.3691 - accuracy: 0.8289 - val_loss: 0.4510 - val_accuracy: 0.8045\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.3363 - accuracy: 0.8521 - val_loss: 0.4677 - val_accuracy: 0.8005\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.3452 - accuracy: 0.8529 - val_loss: 0.5129 - val_accuracy: 0.7795\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 39s 156ms/step - loss: 0.3066 - accuracy: 0.8664 - val_loss: 0.4932 - val_accuracy: 0.7930\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 39s 156ms/step - loss: 0.3029 - accuracy: 0.8663 - val_loss: 0.4591 - val_accuracy: 0.8120\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.2894 - accuracy: 0.8727 - val_loss: 0.5037 - val_accuracy: 0.7970\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.2872 - accuracy: 0.8779 - val_loss: 0.5482 - val_accuracy: 0.7935\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 39s 156ms/step - loss: 0.2707 - accuracy: 0.8871 - val_loss: 0.5354 - val_accuracy: 0.7945\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 39s 155ms/step - loss: 0.2607 - accuracy: 0.8919 - val_loss: 0.5319 - val_accuracy: 0.7985\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4ef1ecd510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcZ8uPg_-apo"
      },
      "source": [
        "model.save('clf.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDqr6U08BYz6"
      },
      "source": [
        "## Making a Single Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bvw_S9Q-m68"
      },
      "source": [
        "#model = keras.models.load_model('clf.h5')\n",
        "\n",
        "test_image = image.load_img('/content/drive/MyDrive/CNN_Model/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = model.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'Dog'\n",
        "else:\n",
        "  prediction = 'Cat'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq_yl8K0BXHZ",
        "outputId": "d6142168-1757-4ea8-82d5-ddfb8e4e113c"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW0FrdLtMXvB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}